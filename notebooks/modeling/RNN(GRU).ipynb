{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b7f3fd-f153-4bf7-a097-c23b001c69ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2aa0f85-e202-4911-a2b3-18bc4eed4d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (0.12.19)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (59.5.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.8/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.6.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a318010f-4894-4eaf-b112-279e7932b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366b8720-6114-4e63-8c0d-5277fdc632ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"dark\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771ff16b-ef87-47f8-abf0-1bdbedea72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385ad674-d814-499e-8779-c95e10d26cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.8/site-packages (8.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install more-itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743ea376-883c-4b39-aa0f-362fec54aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from more_itertools import take\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "094d24aa-8738-41fe-80a3-44b4a446f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f289bc-135f-45bc-b811-a1619f854338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=1234):\n",
    "    \"\"\"set seeds for reproducibility\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # For multi-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f9cda8-fb17-4e19-9c78-629d7225d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f727fdb-5dc2-4762-ae2b-1f148777a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "device = torch.device(\"cuda\" if(\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be43d92-2dd2-4990-a624-d23898f39d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../../datasets/V1/train.parquet\")\n",
    "val_df = pd.read_parquet(\"../../datasets/V1/valid.parquet\")\n",
    "test_df = pd.read_parquet(\"../../datasets/V1/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33243502-97a9-4cc0-86fb-e986a7e53923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target\n",
    "X_train = train_df.text.to_numpy()\n",
    "y_train = train_df.rating\n",
    "\n",
    "X_val =  val_df.text.to_numpy()\n",
    "y_val = val_df.rating\n",
    "\n",
    "X_test = test_df.text.to_numpy()\n",
    "y_test = test_df.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f951b76-fe4b-4d51-ac0d-48345b35377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (31499,), y_train:(31499,)\n",
      "X_val: (6750,), y_val:(6750,)\n",
      "X_test: (6751,), y_test:(6751,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, y_train:{y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val:{y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "195abe70-4a74-4942-b6ad-50cd0cc580aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: python wrong codepython beginner trying execute following \n",
      "print( old enough vote please enter age )\n",
      "input()\n",
      "\n",
      "age 18\n",
      "\n",
      "age 18 \n",
      " print( must 18 vote )\n",
      "\n",
      "elif age 18 \n",
      " print ( voting age )\n",
      "\n",
      "\n",
      "run program prints voting age matter low number input someone help sure really basic stuck \n",
      "\n",
      "thanks -> LQ_EDIT\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample: {X_train[0]} -> {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca402bdb-2023-4910-adc0-b028e3f41556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder to encode class labels\n",
    "class LabelEncoder(object):\n",
    "    \"\"\"Encode labels into unqiue ids/integers\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}\n",
    "        self.index_to_class = {v:k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "    \n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v:k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "    \n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros(len(y), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "    \n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "            \n",
    "        return classes\n",
    "    \n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\"class_to_index\": self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29e908f-f7de-4b5f-8898-052f8f0bd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder.load(\"../../artifacts/label_encoder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a98565b-e80e-4321-8b45-fca597e9c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all our labels\n",
    "y_train = label_encoder.encode(y_train)\n",
    "\n",
    "y_val = label_encoder.encode(y_val)\n",
    "\n",
    "y_test = label_encoder.encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46cda7a0-b9b9-42f0-901d-1c02562684cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [10499 10500 10500]\n",
      " weights: {0: 9.524716639679969e-05, 1: 9.523809523809524e-05, 2: 9.523809523809524e-05}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print(f\"counts: {counts}\\n weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4745fa14-cb47-4389-b91d-46b275466e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "class Tokenizer(object):\n",
    "    def __init__(self, char_level, num_tokens=None, pad_token=\"<PAD>\",\n",
    "                oov_token=\"<UNK\", token_to_index=None):\n",
    "        self.char_level = char_level\n",
    "        self.separator = \"\" if self.char_level else \" \"\n",
    "        if num_tokens: num_tokens -=2 # pad token and unk token excluded\n",
    "        self.num_tokens = num_tokens\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        \n",
    "        if not token_to_index:\n",
    "            token_to_index = {pad_token: 0, oov_token: 1}\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {v:k for k, v in self.token_to_index.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        if not self.char_level:\n",
    "            texts = [text.split(' ') for text in texts]\n",
    "        all_tokens = [token for text in texts for token in text]\n",
    "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
    "        self.min_token_freq = counts[-1][1]\n",
    "        \n",
    "        for token, count in counts:\n",
    "            index = len(self)\n",
    "            self.token_to_index[token] = index\n",
    "            self.index_to_token[index] = token\n",
    "        return self\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            if not self.char_level:\n",
    "                text = text.split(\" \")\n",
    "            sequence = []\n",
    "            for token in text:\n",
    "                sequence.append(self.token_to_index.get(\n",
    "                    token, self.token_to_index[self.oov_token]\n",
    "                ))\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "            \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = []\n",
    "            for index in sequence:\n",
    "                text.append(self.index_to_token.get(\n",
    "                    index, self.oov_token\n",
    "                ))\n",
    "            texts.append(self.separator.join([token for token in text]))\n",
    "        return texts\n",
    "    \n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\n",
    "                \"char_level\": self.char_level,\n",
    "                \"oov_token\": self.oov_token,\n",
    "                \"token_to_index\": self.token_to_index\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29dbc3d1-9d29-4f28-8b75-d8c5cf80def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the full vocabulary size of training data\n",
    "def check_vocab_size(texts):\n",
    "    texts = [text.split(' ') for text in texts]\n",
    "    all_tokens = [token for text in texts for token in text]\n",
    "    # print(len(all_tokens))\n",
    "    vocab_counts = Counter(all_tokens).most_common(None)\n",
    "    # print(vocab_counts)\n",
    "    print(f\"Total vocabulary size is: {len(vocab_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df990bb4-719b-4dd6-9683-2c2b3fcf94c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size is: 243250\n"
     ]
    }
   ],
   "source": [
    "check_vocab_size(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db540d4d-e205-4041-b5d2-bde7f00a23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=5000)>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
    "tokenizer.fit_on_texts(texts=X_train)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9aaa974-30ca-4ea0-a68f-e0426ab326f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(Path(\"../../artifacts/rnn-tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c796be1-6d74-4c62-9742-df67d89a7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66f3589-b1ef-4d7a-ad90-9aebc481f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malokpadhi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/stackoverflow/notebooks/modeling/wandb/run-20220628_050945-1bezp1pn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alokpadhi/stackoverflow-quality/runs/1bezp1pn\" target=\"_blank\">RNN-Tokenizer</a></strong> to <a href=\"https://wandb.ai/alokpadhi/stackoverflow-quality\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f7a6dd23b50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_run = wandb.init(project=\"stackoverflow-quality\", name=\"RNN-Tokenizer\")\n",
    "token_art = wandb.Artifact(\"RNN-Tokenizer\", type=\"preprocessed_data\", metadata=dict(num_tokens=5000))\n",
    "token_art.add_file(\"../../artifacts/rnn-tokenizer.json\")\n",
    "token_run.log_artifact(token_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3a0cf14-35e6-45d6-a284-351edad82030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to indices: \n",
      " (Preprocessed) -> python wrong <UNK beginner trying execute following <UNK old enough <UNK please enter age <UNK <UNK 18 \n",
      " print( must 18 <UNK <UNK age 18 \n",
      " print ( <UNK age <UNK program prints <UNK age matter low number input someone help sure really basic stuck \n",
      "\n",
      "thanks\n",
      " (Tokenized) -> [93, 241, 1, 1256, 72, 654, 88, 1, 899, 1586, 1, 95, 103, 742, 1, 1, 535, 3, 311, 422, 535, 1, 1, 742, 535, 3, 188, 22, 1, 742, 1, 164, 1187, 1, 742, 1760, 2134, 75, 62, 375, 53, 347, 439, 613, 1094, 900]\n"
     ]
    }
   ],
   "source": [
    "# convert texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
    "print(\"Text to indices: \\n\"\n",
    "     f\" (Preprocessed) -> {preprocessed_text}\\n\"\n",
    "     f\" (Tokenized) -> {X_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "209e3485-02e4-4c70-a9ac-7a9b2bce482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to max_length\n",
    "def pad_sequences(sequences, max_seq_len=0):\n",
    "    \"\"\"Pad sequences to max_length in sequence\"\"\"\n",
    "    # max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
    "    # num_classes = sequences[0].shape[-1]\n",
    "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        if len(sequence) < max_seq_len:\n",
    "            padded_sequences[i][:len(sequence)] = sequence\n",
    "        else:\n",
    "            # print(sequence)\n",
    "            padded_sequences[i][:max_seq_len] = sequence[:200]\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f9558a-683a-4516-9d0f-52fce98a236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return [X, len(X), y]\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        batch = np.array(batch)\n",
    "        X = batch[:, 0]\n",
    "        seq_lens = batch[:, 1]\n",
    "        y = batch[:, 2]\n",
    "        \n",
    "        X = pad_sequences(X, 200)\n",
    "        \n",
    "        seq_lens = np.array([seq_len if seq_len < 200 else 200 for seq_len in seq_lens])\n",
    "        X = torch.LongTensor(X.astype(np.int32))\n",
    "        seq_lens = torch.LongTensor(seq_lens.astype(np.int32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "        \n",
    "        return X, seq_lens, y\n",
    "    \n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21f8f0e7-04a7-493f-bab6-ff182a4f53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = Dataset(X=X_train, y=y_train)\n",
    "val_dataset = Dataset(X=X_val, y=y_val)\n",
    "test_dataset = Dataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0163f3cf-db0d-4822-889d-7fdd2e210086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dasets: \n",
      "Train Dataset: <Dataset(N=31499)>\n",
      "Val Dataset: <Dataset(N=6750)>\n",
      "Test Dataset: <Dataset(N=6751)>\n",
      "Sample Data:\n",
      "X: [93, 241, 1, 1256, 72, 654, 88, 1, 899, 1586, 1, 95, 103, 742, 1, 1, 535, 3, 311, 422, 535, 1, 1, 742, 535, 3, 188, 22, 1, 742, 1, 164, 1187, 1, 742, 1760, 2134, 75, 62, 375, 53, 347, 439, 613, 1094, 900]\n",
      "seq_len: 46\n",
      "y 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Dasets: \\n\"\n",
    "     f\"Train Dataset: {train_dataset.__str__()}\\n\"\n",
    "     f\"Val Dataset: {val_dataset.__str__()}\\n\"\n",
    "     f\"Test Dataset: {test_dataset.__str__()}\\n\"\n",
    "     f\"Sample Data:\\n\"\n",
    "     f\"X: {train_dataset[0][0]}\\n\"\n",
    "     f\"seq_len: {train_dataset[0][1]}\\n\"\n",
    "     f\"y {train_dataset[0][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adadbe1b-c55a-4ee0-be4e-33a9cabc0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0ac9b33-9842-4f6b-bb0f-5675f1f5bb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "X: [64, 200]\n",
      "seq_lens: [64]\n",
      "y: [64]\n",
      "Sample point: \n",
      "X: tensor([  55,  207, 1121,  609, 1298,  522,  457,  421,  511, 2226, 2641, 1271,\n",
      "         184,    1,  207, 1121,  609, 1298,  522,  457,  421,  511, 2226, 2641,\n",
      "        1271,  184,  522, 2464,  241,    1,   98,    1,    1,   13,  616,    3,\n",
      "         620, 1746, 1544, 1026,    3,  176,    1,    3,  133,    1,    3,  700,\n",
      "         351,    1,    3,  700,  297,    1,    3,  283,   61, 2564,    1,    1,\n",
      "          11, 2090,    1,  190,  296,    1,   10,  189,    1,    1,    1,   50,\n",
      "         359, 4075,    1,    1,    1,    3,  522, 2302, 1774, 1774, 1092,    3,\n",
      "         283,  146, 2746,    3,  283,  361,  441,    3, 1087, 1006,    1,    3,\n",
      "        2148, 1006,    1,    3, 1006,    1,    3,   13, 2954,  332,    1, 2737,\n",
      "           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0], device='cpu')\n",
      "Seq_len: 109\n",
      "y: 2\n"
     ]
    }
   ],
   "source": [
    "batch_X, batch_seq_lens, batch_y = next(iter(test_dataloader))\n",
    "print(\"Sample batch:\\n\"\n",
    "     f\"X: {list(batch_X.size())}\\n\"\n",
    "     f\"seq_lens: {list(batch_seq_lens.size())}\\n\"\n",
    "     f\"y: {list(batch_y.size())}\\n\"\n",
    "     f\"Sample point: \\n\"\n",
    "     f\"X: {batch_X[0]}\\n\"\n",
    "     f\"Seq_len: {batch_seq_lens[0]}\\n\"\n",
    "     f\"y: {batch_y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47b132a7-dcd7-44c6-a39d-73f51a6d3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "    def train_step(self, dataloader):\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "        \n",
    "        # iterate over batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            batch = [item.to(device) for item in batch]\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()\n",
    "            z = self.model(inputs)\n",
    "            J = self.loss_fn(z, targets)\n",
    "            J.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            loss += (J.detach().item() - loss) / (i+1)\n",
    "        return loss\n",
    "    \n",
    "    def eval_step(self, dataloader):\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                batch = [item.to(device) for item in batch]\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                \n",
    "                z = self.model(inputs)\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "                \n",
    "                loss += (J - loss) / (i + 1)\n",
    "                \n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "                \n",
    "            \n",
    "            return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "        \n",
    "    def predict_step(self, dataloader):\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                \n",
    "                z = self.model(inputs)\n",
    "                \n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "            return np.vstack(y_probs)\n",
    "    \n",
    "    def train(self, num_epochs, patience, train_dataloder, val_dataloader, wandb_run):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"[INFO] Epoch: {epoch+1} training started\")\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            print(f\"[INFO] Epoch: {epoch+1} training finished\")\n",
    "            print(f\"[INFO] Epoch: {epoch+1} evaluation started\")\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            print(f\"[INFO] Epoch: {epoch+1} evaluation finished\")\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                wandb_run.summary[\"Best val loss\"] = best_val_loss\n",
    "                _patience = patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            \n",
    "            if not _patience:\n",
    "                print(\"Stopping Early\")\n",
    "                break\n",
    "            print(f\"[INFO] Logging wandb\")\n",
    "            wandb.log({\"train_loss\": train_loss})\n",
    "            wandb.log({\"valid_loss\": val_loss})\n",
    "            \n",
    "            print(\n",
    "                f\"Epoch: {epoch+1}\\n\"\n",
    "                f\"\\t train_loss: {train_loss:.3f}, \"\n",
    "                f\"\\t val_loss: {val_loss: .3f}, \"\n",
    "                f\"\\t LR: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e21deb23-1c9c-4f16-8924-acecc1aa49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "057865c0-9804-463c-aebe-f56d432cccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim, hidden_dim, dropout, \n",
    "                 num_classes, pretrained_embeddings=None, freeze_embeddings=False, padding_idx=0):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        if pretrained_embeddings is None:\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size, padding_idx=padding_idx\n",
    "            )\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx, _weight=pretrained_embeddings\n",
    "            )\n",
    "\n",
    "        if freeze_embeddings:\n",
    "            self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        self.gru = nn.GRU(embedding_dim, rnn_hidden_dim,\n",
    "                         batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x_in, seq_lens = inputs\n",
    "        x_in = self.embeddings(x_in)\n",
    "        # print(seq_lens.shape)\n",
    "        packed_in = pack_padded_sequence(x_in, seq_lens.to('cpu'), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, h_n = self.gru(packed_in)\n",
    "        \n",
    "        z = torch.cat([h_n[0, :, :], h_n[1, :,:]], dim=1)\n",
    "        \n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3f50f6e-70d8-4266-b8ec-2d8bd5dbb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(embedding_file):\n",
    "    embeddings = {}\n",
    "    with open(embedding_file, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = embedding\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e4aa302-44f5-488b-b75e-39411e813238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(embeddings, word_index, embedding_dim):\n",
    "    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af624a7a-9a22-4d9f-a90a-28bfac5f5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "RNN_HIDDEN_DIM = 128\n",
    "HIDDEN_DIM = 100\n",
    "NUM_CLASSES = len(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87fa5a82-5447-4f6e-ad11-2af67c671f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get glove pre-trained embeddings\n",
    "# !wget https://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44684bc1-6908-4772-97f2-31a68f971e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Embeddings(words=5000, dim=100))>\n"
     ]
    }
   ],
   "source": [
    "embedding_file = \"../../embeddings/glove.6B.{0}d.txt\".format(EMBEDDING_DIM)\n",
    "glove_embeddings = load_glove_embeddings(embedding_file=embedding_file)\n",
    "embedding_matrix = make_embedding_matrix(embeddings=glove_embeddings, word_index=tokenizer.token_to_index,\n",
    "                                        embedding_dim=EMBEDDING_DIM)\n",
    "print(f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]}))>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1aee57c-77e7-4c0e-8155-0247df96ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
    "FREEZE_EMBEDDINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "162a85b7-32eb-4d8a-9e45-ffd42143c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8e30527-161c-4aaf-a54e-e68e6b0a0365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of GRU(\n",
      "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
      "  (gru): GRU(100, 128, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=3, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = GRU(embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "           rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM,\n",
    "           dropout=DROPOUT_P, num_classes=NUM_CLASSES, pretrained_embeddings=PRETRAINED_EMBEDDINGS,\n",
    "            freeze_embeddings=FREEZE_EMBEDDINGS\n",
    "           )\n",
    "model = model.to(device)\n",
    "print(model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cf24604-1530-47fa-a914-152e66c13e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01deeaf5-d63d-49fc-91fc-eea8520be9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 4\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9706fe5d-fab6-4400-9d45-7efa828f4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79bfdd43-13d1-41a4-a1b7-abe66ea4e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = dict(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    patience=PATIENCE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    target_classes=NUM_CLASSES,\n",
    "    optimizer=\"Adam\",\n",
    "    scheduler=\"ReduceLROnPlateau\",\n",
    "    loss_function=\"Cross Entropy\",\n",
    "    embedding=\"glove\",\n",
    "    embedding_dim=100,\n",
    "    model=\"GRU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8098d161-f4c8-4070-ba04-133f53e4c9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/stackoverflow/notebooks/modeling/wandb/run-20220628_052657-1n6tq9gm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alokpadhi/stackoverflow-quality/runs/1n6tq9gm\" target=\"_blank\">RNN</a></strong> to <a href=\"https://wandb.ai/alokpadhi/stackoverflow-quality\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"stackoverflow-quality\", config=CONFIG, name=\"RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "232f65f0-91f0-4eac-86a7-cc50ecaefa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, device=device, loss_fn=loss_fn,\n",
    "                 optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eee6fd57-52e6-4a49-8162-4def1a8ad1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch: 1 training started\n",
      "[INFO] Epoch: 1 training finished\n",
      "[INFO] Epoch: 1 evaluation started\n",
      "[INFO] Epoch: 1 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 1\n",
      "\t train_loss: 0.156, \t val_loss:  0.354, \t LR: 1.00E-05, _patience: 4\n",
      "[INFO] Epoch: 2 training started\n",
      "[INFO] Epoch: 2 training finished\n",
      "[INFO] Epoch: 2 evaluation started\n",
      "[INFO] Epoch: 2 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 2\n",
      "\t train_loss: 0.155, \t val_loss:  0.357, \t LR: 1.00E-06, _patience: 3\n",
      "[INFO] Epoch: 3 training started\n",
      "[INFO] Epoch: 3 training finished\n",
      "[INFO] Epoch: 3 evaluation started\n",
      "[INFO] Epoch: 3 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 3\n",
      "\t train_loss: 0.151, \t val_loss:  0.349, \t LR: 1.00E-06, _patience: 4\n",
      "[INFO] Epoch: 4 training started\n",
      "[INFO] Epoch: 4 training finished\n",
      "[INFO] Epoch: 4 evaluation started\n",
      "[INFO] Epoch: 4 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 4\n",
      "\t train_loss: 0.150, \t val_loss:  0.349, \t LR: 1.00E-06, _patience: 4\n",
      "[INFO] Epoch: 5 training started\n",
      "[INFO] Epoch: 5 training finished\n",
      "[INFO] Epoch: 5 evaluation started\n",
      "[INFO] Epoch: 5 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 5\n",
      "\t train_loss: 0.150, \t val_loss:  0.349, \t LR: 1.00E-06, _patience: 3\n",
      "[INFO] Epoch: 6 training started\n",
      "[INFO] Epoch: 6 training finished\n",
      "[INFO] Epoch: 6 evaluation started\n",
      "[INFO] Epoch: 6 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 6\n",
      "\t train_loss: 0.150, \t val_loss:  0.349, \t LR: 1.00E-07, _patience: 2\n",
      "[INFO] Epoch: 7 training started\n",
      "[INFO] Epoch: 7 training finished\n",
      "[INFO] Epoch: 7 evaluation started\n",
      "[INFO] Epoch: 7 evaluation finished\n",
      "[INFO] Logging wandb\n",
      "Epoch: 7\n",
      "\t train_loss: 0.150, \t val_loss:  0.349, \t LR: 1.00E-07, _patience: 1\n",
      "[INFO] Epoch: 8 training started\n",
      "[INFO] Epoch: 8 training finished\n",
      "[INFO] Epoch: 8 evaluation started\n",
      "[INFO] Epoch: 8 evaluation finished\n",
      "Stopping Early\n"
     ]
    }
   ],
   "source": [
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader, run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a303292-50d8-43c5-ba53-0945b3353ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, classes):\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "    \n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1-score\"] = metrics[2]\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "    \n",
    "    # Per-class performance\n",
    "    class_metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"precision\": class_metrics[0][i],\n",
    "            \"recall\": class_metrics[1][i],\n",
    "            \"f1-score\": class_metrics[2][i],\n",
    "            \"num_samples\": np.float64(class_metrics[3][i]),\n",
    "        }\n",
    "        \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6d05018-43f7-4199-874b-c1e51ca5761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d140cfea-fd40-4fe7-9e56-4604575eba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8696557165854493,\n",
      "  \"recall\": 0.8696489408976448,\n",
      "  \"f1-score\": 0.8696316467728067,\n",
      "  \"num_samples\": 6751.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "performance = get_metrics(y_true, y_pred, classes=label_encoder.classes)\n",
    "print(json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c428854-ee83-4bbd-9af9-768b595f1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({\"precision\": performance[\"overall\"][\"precision\"], \"recall\": performance[\"overall\"][\"recall\"], \"f1-score\": performance[\"overall\"][\"f1-score\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d273549-6a07-4124-a055-9e798f1350be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.684 MB of 2.684 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">RNN</strong>: <a href=\"https://wandb.ai/alokpadhi/stackoverflow-quality/runs/3x5rrduc\" target=\"_blank\">https://wandb.ai/alokpadhi/stackoverflow-quality/runs/3x5rrduc</a><br/>Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220628_052153-3x5rrduc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4084fc68-4223-4469-872d-c1de8239ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = Path(\"../../model-artifacts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3802ab85-9b17-4630-b814-f6bc5cc0f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(best_model.state_dict(), Path(model_artifact, \"rnn-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "317ff91f-a73c-4f13-992c-f477f5045278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f7a4682df10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_art = wandb.Artifact(f\"{wandb.run.name}_{wandb.run.id}\", type=\"model\", metadata=CONFIG)\n",
    "model_art.add_file(\"../../model-artifacts/rnn-model.pt\")\n",
    "run.log_artifact(model_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424ce67-5cad-4e2f-ba83-c9281d5ec41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
